{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "#sigmoid_function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# J_cost function\n",
    "def J_cost(X, y, beta):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X: train data, shape: n*p\n",
    "    :param y: label, shape n*1\n",
    "    :param beta: shape (p + 1)*1\n",
    "    :return: result of J_cost\n",
    "    \"\"\"\n",
    "    X_hat = np.c_[X, np.ones((X.shape[0], 1))]\n",
    "    beta = beta.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    l_beta = -y * np.dot(X_hat, beta) + np.log(1 + np.exp(np.dot(X_hat, beta)))\n",
    "\n",
    "    return l_beta.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "#gradient_descent function\n",
    "def derivative_1(X, y, beta):\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    :param X: train data, shape: n*p\n",
    "    :param y: abel, shape n*1\n",
    "    :param beta: shape (p + 1)*1\n",
    "    :return derivate_1 of J_cost\n",
    "    \"\"\"\n",
    "    X_hat = np.c_[X, np.ones((X.shape[0], 1))]\n",
    "    beta = beta.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    p1 = sigmoid(np.dot(X_hat, beta))\n",
    "\n",
    "    gra = (-X_hat * (y - p1)).sum(0)\n",
    "\n",
    "    return gra.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def derivative_2(X, y, beta):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X: train data, shape: n*p\n",
    "    :param y: abel, shape n*1\n",
    "    :param beta: shape (p + 1)*1\n",
    "    :return: derivate_2 of J_cost\n",
    "    \"\"\"\n",
    "    X_hat = np.c_[X, np.ones((X.shape[0], 1))]\n",
    "    beta = beta.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    p1 = sigmoid(np.dot(X_hat, beta))\n",
    "    m, n = X.shape\n",
    "    P = np.eye(m) * p1 * (1 - p1)  #对角矩阵\n",
    "    return np.dot(np.dot(X_hat.T, P), X_hat)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def update_parameters_newton(X, y, beta, num_iterations, print_cost):\n",
    "    \"\"\"\n",
    "    update beta\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param beta:\n",
    "    :param num_iterations: iterative numbers\n",
    "    :param print_cost:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        d1 = derivative_1(X, y, beta)\n",
    "        d2 = derivative_2(X, y, beta)\n",
    "        beta = beta - np.dot(np.linalg.inv(d2), d1)\n",
    "\n",
    "        if (i % 10 == 0) & print_cost:\n",
    "            print('{}th iteration, cost is {}'.format(i, J_cost(X, y, beta)))\n",
    "    return beta\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "def init(n):\n",
    "    beta = np.random.randn(n, 1) * 0.5 + 1\n",
    "    return beta\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def predict(X, beta):\n",
    "    X_hat = np.c_[X, np.ones((X.shape[0], 1))]\n",
    "    p1 = sigmoid(np.dot(X_hat, beta))\n",
    "\n",
    "    p1[p1 >= 0.5] = 1\n",
    "    p1[p1 < 0.5] = 0\n",
    "\n",
    "    return p1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration, cost is 8.79670199145312\n",
      "10th iteration, cost is 8.683660584232864\n",
      "20th iteration, cost is 8.683660584232866\n",
      "30th iteration, cost is 8.683660584232864\n",
      "40th iteration, cost is 8.683660584232866\n",
      "50th iteration, cost is 8.683660584232864\n",
      "60th iteration, cost is 8.683660584232864\n",
      "70th iteration, cost is 8.683660584232864\n",
      "80th iteration, cost is 8.683660584232864\n",
      "90th iteration, cost is 8.683660584232864\n",
      "100th iteration, cost is 8.683660584232866\n",
      "110th iteration, cost is 8.683660584232864\n",
      "120th iteration, cost is 8.683660584232864\n",
      "130th iteration, cost is 8.683660584232864\n",
      "140th iteration, cost is 8.683660584232866\n",
      "150th iteration, cost is 8.683660584232864\n",
      "160th iteration, cost is 8.683660584232866\n",
      "170th iteration, cost is 8.683660584232864\n",
      "180th iteration, cost is 8.683660584232864\n",
      "190th iteration, cost is 8.683660584232866\n",
      "200th iteration, cost is 8.683660584232864\n",
      "210th iteration, cost is 8.683660584232866\n",
      "220th iteration, cost is 8.683660584232864\n",
      "230th iteration, cost is 8.683660584232866\n",
      "240th iteration, cost is 8.683660584232864\n",
      "250th iteration, cost is 8.683660584232864\n",
      "260th iteration, cost is 8.683660584232864\n",
      "270th iteration, cost is 8.683660584232864\n",
      "280th iteration, cost is 8.683660584232864\n",
      "290th iteration, cost is 8.683660584232866\n",
      "300th iteration, cost is 8.683660584232864\n",
      "310th iteration, cost is 8.683660584232864\n",
      "320th iteration, cost is 8.683660584232864\n",
      "330th iteration, cost is 8.683660584232866\n",
      "340th iteration, cost is 8.683660584232864\n",
      "350th iteration, cost is 8.683660584232866\n",
      "360th iteration, cost is 8.683660584232864\n",
      "370th iteration, cost is 8.683660584232864\n",
      "380th iteration, cost is 8.683660584232866\n",
      "390th iteration, cost is 8.683660584232864\n",
      "400th iteration, cost is 8.683660584232866\n",
      "410th iteration, cost is 8.683660584232864\n",
      "420th iteration, cost is 8.683660584232866\n",
      "430th iteration, cost is 8.683660584232864\n",
      "440th iteration, cost is 8.683660584232864\n",
      "450th iteration, cost is 8.683660584232864\n",
      "460th iteration, cost is 8.683660584232864\n",
      "470th iteration, cost is 8.683660584232864\n",
      "480th iteration, cost is 8.683660584232866\n",
      "490th iteration, cost is 8.683660584232864\n",
      "500th iteration, cost is 8.683660584232864\n",
      "510th iteration, cost is 8.683660584232864\n",
      "520th iteration, cost is 8.683660584232866\n",
      "530th iteration, cost is 8.683660584232864\n",
      "540th iteration, cost is 8.683660584232866\n",
      "550th iteration, cost is 8.683660584232864\n",
      "560th iteration, cost is 8.683660584232864\n",
      "570th iteration, cost is 8.683660584232866\n",
      "580th iteration, cost is 8.683660584232864\n",
      "590th iteration, cost is 8.683660584232866\n",
      "600th iteration, cost is 8.683660584232864\n",
      "610th iteration, cost is 8.683660584232866\n",
      "620th iteration, cost is 8.683660584232864\n",
      "630th iteration, cost is 8.683660584232864\n",
      "640th iteration, cost is 8.683660584232864\n",
      "650th iteration, cost is 8.683660584232864\n",
      "660th iteration, cost is 8.683660584232864\n",
      "670th iteration, cost is 8.683660584232866\n",
      "680th iteration, cost is 8.683660584232864\n",
      "690th iteration, cost is 8.683660584232864\n",
      "700th iteration, cost is 8.683660584232864\n",
      "710th iteration, cost is 8.683660584232866\n",
      "720th iteration, cost is 8.683660584232864\n",
      "730th iteration, cost is 8.683660584232866\n",
      "740th iteration, cost is 8.683660584232864\n",
      "750th iteration, cost is 8.683660584232864\n",
      "760th iteration, cost is 8.683660584232866\n",
      "770th iteration, cost is 8.683660584232864\n",
      "780th iteration, cost is 8.683660584232866\n",
      "790th iteration, cost is 8.683660584232864\n",
      "800th iteration, cost is 8.683660584232866\n",
      "810th iteration, cost is 8.683660584232864\n",
      "820th iteration, cost is 8.683660584232864\n",
      "830th iteration, cost is 8.683660584232864\n",
      "840th iteration, cost is 8.683660584232864\n",
      "850th iteration, cost is 8.683660584232864\n",
      "860th iteration, cost is 8.683660584232866\n",
      "870th iteration, cost is 8.683660584232864\n",
      "880th iteration, cost is 8.683660584232864\n",
      "890th iteration, cost is 8.683660584232864\n",
      "900th iteration, cost is 8.683660584232866\n",
      "910th iteration, cost is 8.683660584232864\n",
      "920th iteration, cost is 8.683660584232866\n",
      "930th iteration, cost is 8.683660584232864\n",
      "940th iteration, cost is 8.683660584232864\n",
      "950th iteration, cost is 8.683660584232866\n",
      "960th iteration, cost is 8.683660584232864\n",
      "970th iteration, cost is 8.683660584232866\n",
      "980th iteration, cost is 8.683660584232864\n",
      "990th iteration, cost is 8.683660584232866\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "data = [[0.697, 0.460, 1], [0.774, 0.376, 1], [0.634, 0.264, 1], [0.608, 0.318, 1], [0.556, 0.215, 1],\n",
    "            [0.403, 0.237, 1], [0.481, 0.149, 1], [0.437, 0.211, 1],\n",
    "            [0.666, 0.091, 0], [0.243, 0.267, 0], [0.245, 0.057, 0], [0.343, 0.099, 0], [0.639, 0.161, 0],\n",
    "            [0.657, 0.198, 0], [0.360, 0.370, 0], [0.593, 0.042, 0], [0.719, 0.103, 0]]\n",
    "data = np.array(data)\n",
    "good_watermelon = data[:, 2] == 1\n",
    "bad_watermelon = data[:, 2] == 0\n",
    "X = data[:,0 : 2].astype(float)\n",
    "y = data[:, 2]\n",
    "m, n = data.shape\n",
    "beta = init(n)\n",
    "beta = update_parameters_newton(X, y,beta = beta, num_iterations = 1000, print_cost = True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "def accuary(X, y, beta):\n",
    "    acc = 0.0\n",
    "    X_hat = np.c_[X, np.ones((X.shape[0], 1))]\n",
    "    y_pred = sigmoid(np.dot(X_hat,beta))\n",
    "    for i in range(len(X_hat)):\n",
    "        if (y_pred[i] >= 0.5 and y[i] == 1) or (y_pred[i] < 0.5 and y[i] == 0):\n",
    "            acc += 1\n",
    "\n",
    "    return acc / len(X)\n",
    "acc = accuary(X, y, beta)\n",
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
